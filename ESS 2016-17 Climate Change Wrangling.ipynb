{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44387 entries, 0 to 44386\n",
      "Data columns (total 39 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  44387 non-null  int64  \n",
      " 1   name        44387 non-null  object \n",
      " 2   essround    44387 non-null  int64  \n",
      " 3   edition     44387 non-null  float64\n",
      " 4   proddate    44387 non-null  object \n",
      " 5   idno        44344 non-null  float64\n",
      " 6   cntry       44387 non-null  object \n",
      " 7   eneffap     43276 non-null  float64\n",
      " 8   rdcenr      43836 non-null  float64\n",
      " 9   cflsenr     43435 non-null  float64\n",
      " 10  elgcoal     40690 non-null  float64\n",
      " 11  elgngas     41042 non-null  float64\n",
      " 12  elghydr     41885 non-null  float64\n",
      " 13  elgnuc      40983 non-null  float64\n",
      " 14  elgsun      42587 non-null  float64\n",
      " 15  elgwind     42224 non-null  float64\n",
      " 16  elgbio      39689 non-null  float64\n",
      " 17  wrpwrct     44387 non-null  int64  \n",
      " 18  wrenexp     44387 non-null  int64  \n",
      " 19  wrdpimp     44387 non-null  int64  \n",
      " 20  wrdpfos     44387 non-null  int64  \n",
      " 21  wrntdis     44387 non-null  int64  \n",
      " 22  wrinspw     44387 non-null  int64  \n",
      " 23  wrtcfl      44387 non-null  int64  \n",
      " 24  wrtratc     44387 non-null  int64  \n",
      " 25  clmchng     44387 non-null  int64  \n",
      " 26  clmthgt1    44387 non-null  int64  \n",
      " 27  clmthgt2    44387 non-null  int64  \n",
      " 28  ccnthum     41885 non-null  float64\n",
      " 29  ccrdprs     41927 non-null  float64\n",
      " 30  wrclmch     44387 non-null  int64  \n",
      " 31  ccgdbd      41232 non-null  float64\n",
      " 32  lkredcc     41132 non-null  float64\n",
      " 33  lklmten     41410 non-null  float64\n",
      " 34  gvsrdcc     41078 non-null  float64\n",
      " 35  ownrdcc     41654 non-null  float64\n",
      " 36  inctxff     44387 non-null  int64  \n",
      " 37  sbsrnen     44387 non-null  int64  \n",
      " 38  banhhap     44387 non-null  int64  \n",
      "dtypes: float64(19), int64(17), object(3)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "climate_data = pd.read_csv(r'..\\Climate Data Clean.csv')\n",
    "climate_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>essround</th>\n",
       "      <th>edition</th>\n",
       "      <th>proddate</th>\n",
       "      <th>idno</th>\n",
       "      <th>cntry</th>\n",
       "      <th>eneffap</th>\n",
       "      <th>rdcenr</th>\n",
       "      <th>cflsenr</th>\n",
       "      <th>...</th>\n",
       "      <th>ccrdprs</th>\n",
       "      <th>wrclmch</th>\n",
       "      <th>ccgdbd</th>\n",
       "      <th>lkredcc</th>\n",
       "      <th>lklmten</th>\n",
       "      <th>gvsrdcc</th>\n",
       "      <th>ownrdcc</th>\n",
       "      <th>inctxff</th>\n",
       "      <th>sbsrnen</th>\n",
       "      <th>banhhap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16055</th>\n",
       "      <td>16055</td>\n",
       "      <td>ESS8e02_1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>12846.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29436</th>\n",
       "      <td>29436</td>\n",
       "      <td>ESS8e02_1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>2626.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>603</td>\n",
       "      <td>ESS8e02_1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>Austria</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29239</th>\n",
       "      <td>29239</td>\n",
       "      <td>ESS8e02_1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>2221.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33848</th>\n",
       "      <td>33848</td>\n",
       "      <td>ESS8e02_1</td>\n",
       "      <td>8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>01.12.2018</td>\n",
       "      <td>41121380.0</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       name  essround  edition    proddate        idno  \\\n",
       "16055       16055  ESS8e02_1         8      2.1  01.12.2018     12846.0   \n",
       "29436       29436  ESS8e02_1         8      2.1  01.12.2018      2626.0   \n",
       "603           603  ESS8e02_1         8      2.1  01.12.2018      1167.0   \n",
       "29239       29239  ESS8e02_1         8      2.1  01.12.2018      2221.0   \n",
       "33848       33848  ESS8e02_1         8      2.1  01.12.2018  41121380.0   \n",
       "\n",
       "             cntry  eneffap  rdcenr  cflsenr  ...  ccrdprs  wrclmch  ccgdbd  \\\n",
       "16055      Finland     10.0     2.0      8.0  ...      8.0        3     5.0   \n",
       "29436        Italy      6.0     4.0      5.0  ...      7.0        3     8.0   \n",
       "603        Austria     10.0     5.0      2.0  ...      0.0        2     3.0   \n",
       "29239        Italy      NaN     3.0      8.0  ...     10.0        3     0.0   \n",
       "33848  Netherlands      5.0     3.0      8.0  ...      7.0        5     5.0   \n",
       "\n",
       "       lkredcc  lklmten  gvsrdcc  ownrdcc  inctxff  sbsrnen  banhhap  \n",
       "16055      7.0      2.0      1.0      5.0        3        2        2  \n",
       "29436      6.0      6.0      6.0      6.0        3        3        3  \n",
       "603        3.0      3.0      2.0      3.0        4        4        2  \n",
       "29239      8.0      3.0      0.0      5.0        3        3        1  \n",
       "33848      6.0      4.0      8.0      6.0        2        2        4  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in elgcoal: ['None at all' 'A medium amount' 'A large amount' 'A small amount' nan\n",
      " 'A very large amount']\n",
      "\n",
      "Unique values in elgngas: ['None at all' 'A large amount' 'A small amount' 'A medium amount'\n",
      " 'A very large amount' nan]\n",
      "\n",
      "Unique values in elghydr: ['A very large amount' 'A large amount' 'A medium amount' 'None at all'\n",
      " 'A small amount' nan]\n",
      "\n",
      "Unique values in elgnuc: ['None at all' 'A small amount' 'A medium amount' 'A large amount'\n",
      " 'A very large amount' nan]\n",
      "\n",
      "Unique values in elgsun: ['A very large amount' 'A large amount' 'A medium amount' 'A small amount'\n",
      " nan 'None at all']\n",
      "\n",
      "Unique values in elgwind: ['A very large amount' 'None at all' 'A medium amount' 'A large amount'\n",
      " nan 'A small amount']\n",
      "\n",
      "Unique values in elgbio: ['A very large amount' 'None at all' 'A small amount' 'A medium amount'\n",
      " 'A large amount' nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create mapping dictionary for 'elg' columns\n",
    "elg_mapping_dict = {\n",
    "    1: 'A very large amount',\n",
    "    2: 'A large amount',\n",
    "    3: 'A medium amount',\n",
    "    4: 'A small amount',\n",
    "    5: 'None at all',\n",
    "    6: np.nan, # We will replace the 6 values with NaN as they are not expected\n",
    "    7: np.nan, # We will replace the 7 values with NaN as they are not expected\n",
    "    8: np.nan, # We will replace the 8 values with NaN as they are not expected\n",
    "    9: np.nan, # We will replace the 9 values with NaN as they are not expected\n",
    "}\n",
    "\n",
    "# Get all column names that start with 'elg'\n",
    "elg_cols = [col for col in climate_data.columns if col.startswith('elg')]\n",
    "\n",
    "# Replace the values in the 'elg' columns\n",
    "for col in elg_cols:\n",
    "    climate_data[col] = climate_data[col].replace(elg_mapping_dict)\n",
    "\n",
    "# Check the unique values in the 'elg' columns\n",
    "for col in elg_cols:\n",
    "    print(f\"Unique values in {col}: {climate_data[col].unique()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in wrpwrct: ['Not very worried' 'Not at all worried' 'Somewhat worried' 'Very worried'\n",
      " 'Extremely worried' nan]\n",
      "\n",
      "Unique values in wrenexp: ['Somewhat worried' 'Not very worried' 'Very worried' 'Not at all worried'\n",
      " 'Extremely worried' nan]\n",
      "\n",
      "Unique values in wrdpimp: ['Very worried' 'Not very worried' 'Somewhat worried' 'Not at all worried'\n",
      " nan 'Extremely worried']\n",
      "\n",
      "Unique values in wrdpfos: ['Very worried' 'Somewhat worried' 'Not very worried' nan\n",
      " 'Not at all worried' 'Extremely worried']\n",
      "\n",
      "Unique values in wrntdis: ['Not very worried' 'Not at all worried' 'Somewhat worried' 'Very worried'\n",
      " 'Extremely worried' nan]\n",
      "\n",
      "Unique values in wrinspw: ['Not very worried' 'Not at all worried' 'Somewhat worried' nan\n",
      " 'Extremely worried' 'Very worried']\n",
      "\n",
      "Unique values in wrtcfl: ['Not very worried' 'Somewhat worried' 'Very worried' 'Not at all worried'\n",
      " 'Extremely worried' nan]\n",
      "\n",
      "Unique values in wrtratc: ['Somewhat worried' 'Not very worried' 'Extremely worried'\n",
      " 'Not at all worried' 'Very worried' nan]\n",
      "\n",
      "Unique values in wrclmch: ['Very worried' 'Somewhat worried' 'Not very worried' 'Not at all worried'\n",
      " 'Extremely worried' nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create mapping dictionary for \"wr..\" columns\n",
    "wr_mapping_dict = {\n",
    "    1: 'Not at all worried',\n",
    "    2: 'Not very worried',\n",
    "    3: 'Somewhat worried',\n",
    "    4: 'Very worried',\n",
    "    5: 'Extremely worried',\n",
    "    6: np.nan, # We will replace the 6 values with NaN as they are not expected\n",
    "    7: np.nan, # We will replace the 7 values with NaN as they are not expected\n",
    "    8: np.nan, # We will replace the 8 values with NaN as they are not expected\n",
    "    9: np.nan, # We will replace the 9 values with NaN as they are not expected\n",
    "}\n",
    "\n",
    "# Get all column names that start with 'wr'\n",
    "wr_cols = [col for col in climate_data.columns if col.startswith('wr')]\n",
    "\n",
    "# Replace the values in the 'wr' columns\n",
    "for col in wr_cols:\n",
    "    climate_data[col] = climate_data[col].replace(wr_mapping_dict)\n",
    "\n",
    "# Check the unique values in the 'wr' columns\n",
    "for col in wr_cols:\n",
    "    print(f\"Unique values in {col}: {climate_data[col].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in eneffap: ['8' 'Extremely likely' '9' '6' '7' nan '5' 'Not at all likely' '4' '3'\n",
      " '2' '1']\n",
      "\n",
      "Unique values in lkredcc: ['Extremely likely' '8' '6' '5' '7' nan '3' 'Not at all likely' '2' '4'\n",
      " '9' '1']\n",
      "\n",
      "Unique values in lklmten: ['Not at all likely' '3' '1' '6' 'Extremely likely' '5' '2' '4' '7' nan\n",
      " '8' '9']\n",
      "\n",
      "Unique values in gvsrdcc: ['Not at all likely' '4' '3' '5' '2' '1' '7' '6' nan '8'\n",
      " 'Extremely likely' '9']\n",
      "\n",
      "Unique values in ownrdcc: ['Not at all likely' '6' '1' '7' '3' '8' '2' '4' '5' nan\n",
      " 'Extremely likely' '9']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the columns which have the same likely pattern\n",
    "likely_cols = ['eneffap', 'lkredcc', 'lklmten', 'gvsrdcc', 'ownrdcc']\n",
    "\n",
    "# Create mapping dictionary for likely_cols columns\n",
    "likely_mapping_dict = {\n",
    "    0: 'Not at all likely',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6',\n",
    "    7: '7',\n",
    "    8: '8',\n",
    "    9: '9',\n",
    "    10: 'Extremely likely'\n",
    "}\n",
    "\n",
    "# Replace the values in the likely_cols columns\n",
    "for col in likely_cols:\n",
    "    climate_data[col] = climate_data[col].replace(likely_mapping_dict)\n",
    "\n",
    "# Check the unique values in the likely_cols columns\n",
    "for col in likely_cols:\n",
    "    print(f\"Unique values in {col}: {climate_data[col].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in inctxff: ['Strongly in favour' 'Somewhat against' 'Neither in favour nor against'\n",
      " 'Strongly against' 'Somewhat in favour' nan]\n",
      "\n",
      "Unique values in sbsrnen: ['Strongly in favour' 'Somewhat in favour' 'Neither in favour nor against'\n",
      " 'Strongly against' 'Somewhat against' nan]\n",
      "\n",
      "Unique values in banhhap: ['Somewhat in favour' 'Neither in favour nor against' 'Somewhat against'\n",
      " 'Strongly in favour' 'Strongly against' nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the columns which have the same favour pattern\n",
    "favour_cols = ['inctxff', 'sbsrnen', 'banhhap']\n",
    "\n",
    "# Create mapping dictionary for favour_cols columns\n",
    "favour_mapping_dict = {\n",
    "    1: 'Strongly in favour',\n",
    "    2: 'Somewhat in favour',\n",
    "    3: 'Neither in favour nor against',\n",
    "    4: 'Somewhat against',\n",
    "    5: 'Strongly against',\n",
    "    7: np.nan, # We will replace the 7 values with NaN as they are not expected\n",
    "    8: np.nan, # We will replace the 8 values with NaN as they are not expected\n",
    "    9: np.nan, # We will replace the 9 values with NaN as they are not expected\n",
    "}\n",
    "\n",
    "# Replace the values in the likely_cols columns\n",
    "for col in favour_cols:\n",
    "    climate_data[col] = climate_data[col].replace(favour_mapping_dict)\n",
    "\n",
    "# Check the unique values in the likely_cols columns\n",
    "for col in favour_cols:\n",
    "    print(f\"Unique values in {col}: {climate_data[col].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in rdcenr: ['Often' 'Very often' 'Always' 'Sometimes' 'Hardly ever' 'Never' nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create mapping dictionary for rdcenr column\n",
    "rdcenr_mapping_dict = {\n",
    "    1: 'Never',\n",
    "    2: 'Hardly ever',\n",
    "    3: 'Sometimes',\n",
    "    4: 'Often',\n",
    "    5: 'Very often',\n",
    "    6: 'Always'\n",
    "}\n",
    "\n",
    "# Replace the values in the rdcenr column\n",
    "climate_data['rdcenr'] = climate_data['rdcenr'].replace(rdcenr_mapping_dict)\n",
    "\n",
    "# Check the unique values in the rdcenr column\n",
    "print(f\"Unique values in rdcenr: {climate_data['rdcenr'].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in cflsenr: ['Completely confident' '3' '7' '5' '8' '1' '6' '2' '4' nan\n",
      " 'Not at all confident' '9']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create mapping dictionary for cflsenr column\n",
    "cflsenr_mapping_dict = {\n",
    "    0: 'Not at all confident',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6',\n",
    "    7: '7',\n",
    "    8: '8',\n",
    "    9: '9',\n",
    "    10: 'Completely confident'\n",
    "}\n",
    "\n",
    "# Replace the values in the cflsenr column\n",
    "climate_data['cflsenr'] = climate_data['cflsenr'].replace(cflsenr_mapping_dict)\n",
    "\n",
    "# Check the unique values in the lcflsenr column\n",
    "print(f\"Unique values in cflsenr: {climate_data['cflsenr'].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in clmchng: ['Definitely changing' 'Probably changing' 'Probably not changing'\n",
      " 'Definitely not changing' nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create mapping dictionary for clmchng column\n",
    "clmchng_mapping_dict = {\n",
    "    1: 'Definitely changing',\n",
    "    2: 'Probably changing',\n",
    "    3: 'Probably not changing',\n",
    "    4: 'Definitely not changing',\n",
    "    7: np.nan, # We will replace the 7 values with NaN as they are not expected\n",
    "    8: np.nan, # We will replace the 8 values with NaN as they are not expected\n",
    "    9: np.nan, # We will replace the 9 values with NaN as they are not expected\n",
    "}\n",
    "\n",
    "# Replace the values in the clmchng column\n",
    "climate_data['clmchng'] = climate_data['clmchng'].replace(clmchng_mapping_dict)\n",
    "\n",
    "# Check the unique values in the clmchng column\n",
    "print(f\"Unique values in clmchng: {climate_data['clmchng'].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in ccnthum: ['Mainly by human activity'\n",
      " 'About equally by natural processes and human activity'\n",
      " 'Mainly by natural processes' 'Entirely by human activity' nan\n",
      " 'Entirely by natural processes']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create mapping dictionary for ccnthum column\n",
    "ccnthum_mapping_dict = {\n",
    "    1: 'Entirely by natural processes',\n",
    "    2: 'Mainly by natural processes',\n",
    "    3: 'About equally by natural processes and human activity',\n",
    "    4: 'Mainly by human activity',\n",
    "    5: 'Entirely by human activity'\n",
    "}\n",
    "\n",
    "# Replace the values in the ccnthum column\n",
    "climate_data['ccnthum'] = climate_data['ccnthum'].replace(ccnthum_mapping_dict)\n",
    "\n",
    "# Check the unique values in the ccnthum column\n",
    "print(f\"Unique values in ccnthum: {climate_data['ccnthum'].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in cflsenr: ['8' '7' '6' '5' 'Not at all' '4' '2' '1' 'A great deal' nan '3' '9']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create mapping dictionary for ccrdprs column\n",
    "ccrdprs_mapping_dict = {\n",
    "    0: 'Not at all',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6',\n",
    "    7: '7',\n",
    "    8: '8',\n",
    "    9: '9',\n",
    "    10: 'A great deal'\n",
    "}\n",
    "\n",
    "# Replace the values in the ccrdprs column\n",
    "climate_data['ccrdprs'] = climate_data['ccrdprs'].replace(ccrdprs_mapping_dict)\n",
    "\n",
    "# Check the unique values in the ccrdprs column\n",
    "print(f\"Unique values in cflsenr: {climate_data['ccrdprs'].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in ccgdbd: ['Extremely good' '2' '7' '5' '3' '4' '1' '6' '8' 'Extremely bad' nan '9']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create mapping dictionary for ccgdbd column\n",
    "ccgdbd_mapping_dict = {\n",
    "    0: 'Extremely bad',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6',\n",
    "    7: '7',\n",
    "    8: '8',\n",
    "    9: '9',\n",
    "    10: 'Extremely good'\n",
    "}\n",
    "\n",
    "# Replace the values in the ccgdbd column\n",
    "climate_data['ccgdbd'] = climate_data['ccgdbd'].replace(ccgdbd_mapping_dict)\n",
    "\n",
    "# Check the unique values in the ccgdbd column\n",
    "print(f\"Unique values in ccgdbd: {climate_data['ccgdbd'].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in clmthgt1: [nan 'Very little' 'A lot' 'Some' 'Not at all' 'A great deal']\n",
      "\n",
      "Unique values in clmthgt2: ['A lot' 'Some' 'Very little' 'Not at all' 'A great deal' nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the columns clmthgt1 and clmthgt2\n",
    "clmthgt_cols = ['clmthgt1', 'clmthgt2']\n",
    "\n",
    "# Create mapping dictionary for clmthgt columns\n",
    "clmthgt_mapping_dict = {\n",
    "    1: 'Not at all',\n",
    "    2: 'Very little',\n",
    "    3: 'Some',\n",
    "    4: 'A lot',\n",
    "    5: 'A great deal',\n",
    "    6: np.nan, # We will replace the 7 values with NaN as they are not expected\n",
    "    7: np.nan, # We will replace the 7 values with NaN as they are not expected\n",
    "    8: np.nan, # We will replace the 8 values with NaN as they are not expected\n",
    "    9: np.nan, # We will replace the 9 values with NaN as they are not expected\n",
    "}\n",
    "\n",
    "# Replace the values in the clmthgt columns\n",
    "for col in clmthgt_cols:\n",
    "    climate_data[col] = climate_data[col].replace(clmthgt_mapping_dict)\n",
    "\n",
    "# Check the unique values in the clmthgt columns\n",
    "for col in clmthgt_cols:\n",
    "    print(f\"Unique values in {col}: {climate_data[col].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44387 entries, 0 to 44386\n",
      "Data columns (total 39 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  44387 non-null  int64  \n",
      " 1   name        44387 non-null  object \n",
      " 2   essround    44387 non-null  int64  \n",
      " 3   edition     44387 non-null  float64\n",
      " 4   proddate    44387 non-null  object \n",
      " 5   idno        44344 non-null  float64\n",
      " 6   cntry       44387 non-null  object \n",
      " 7   eneffap     43276 non-null  object \n",
      " 8   rdcenr      43836 non-null  object \n",
      " 9   cflsenr     43435 non-null  object \n",
      " 10  elgcoal     40690 non-null  object \n",
      " 11  elgngas     41042 non-null  object \n",
      " 12  elghydr     41885 non-null  object \n",
      " 13  elgnuc      40983 non-null  object \n",
      " 14  elgsun      42587 non-null  object \n",
      " 15  elgwind     42224 non-null  object \n",
      " 16  elgbio      39689 non-null  object \n",
      " 17  wrpwrct     43945 non-null  object \n",
      " 18  wrenexp     43955 non-null  object \n",
      " 19  wrdpimp     42932 non-null  object \n",
      " 20  wrdpfos     42569 non-null  object \n",
      " 21  wrntdis     43925 non-null  object \n",
      " 22  wrinspw     43675 non-null  object \n",
      " 23  wrtcfl      43829 non-null  object \n",
      " 24  wrtratc     43686 non-null  object \n",
      " 25  clmchng     43289 non-null  object \n",
      " 26  clmthgt1    966 non-null    object \n",
      " 27  clmthgt2    43163 non-null  object \n",
      " 28  ccnthum     41885 non-null  object \n",
      " 29  ccrdprs     41927 non-null  object \n",
      " 30  wrclmch     42654 non-null  object \n",
      " 31  ccgdbd      41232 non-null  object \n",
      " 32  lkredcc     41132 non-null  object \n",
      " 33  lklmten     41410 non-null  object \n",
      " 34  gvsrdcc     41078 non-null  object \n",
      " 35  ownrdcc     41654 non-null  object \n",
      " 36  inctxff     42401 non-null  object \n",
      " 37  sbsrnen     42983 non-null  object \n",
      " 38  banhhap     42699 non-null  object \n",
      "dtypes: float64(2), int64(2), object(35)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# check the entire dataframe\n",
    "climate_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "filepath = Path(r'..\\Climate_Data_Label.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "climate_data.to_csv(filepath)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boolean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
